import torch

# === è·¯å¾„è®¾å®šï¼ˆæ ¹æ®å®é™…è·¯å¾„ä¿®æ”¹ï¼‰ ===
embedding_path = 'Data/embedding/new_items_embedding.pt'

# === åŠ è½½æ•°æ® ===
data = torch.load(embedding_path, map_location='cpu')
index2id = data['index2id']
id2index = data['id2index']

# === æ‰“å°å‰å‡ ä¸ªæ˜ å°„ï¼ˆå¯æ ¹æ®éœ€è¦è°ƒæ•´èŒƒå›´ï¼‰ ===
print("ğŸ“Œ å‰5é¡¹ index2id æ˜ å°„ï¼š")
for i in range(min(5, len(index2id))):
    print(f"  index {i} â†’ id {index2id[i]}")

print("\nğŸ“Œ å‰5é¡¹ id2index æ˜ å°„ï¼š")
for i, (eid, idx) in enumerate(id2index.items()):
    if i >= 5:
        break
    print(f"  id {eid} â†’ index {idx}")

# === å¯é€‰ï¼šåŒå‘ä¸€è‡´æ€§éªŒè¯ ===
print("\nğŸ” ä¸€è‡´æ€§éªŒè¯ï¼š")
ok = True
for i in range(len(index2id)):
    eid = index2id[i]
    if id2index.get(eid) != i:
        print(f"âŒ ä¸ä¸€è‡´: index {i} â†’ id {eid}, ä½† id â†’ {id2index.get(eid)}")
        ok = False
        break
if ok:
    print("âœ… index2id ä¸ id2index æ˜ å°„å®Œå…¨ä¸€è‡´")
